{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24051,"status":"ok","timestamp":1682783802715,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"gUCys6jddVC8","outputId":"016c9037-f590-4271-e244-48c7a9510cee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tXK6a-dIiqAj"},"outputs":[],"source":["import pandas as pd\n","df_train = pd.read_csv('/content/drive/MyDrive/ML/HAI817_Projet_train.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/ML/HAI817_Projet_test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2974,"status":"ok","timestamp":1682783806974,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"RF6BiAf21qW6","outputId":"3ec07c56-fd8c-45a5-b70f-1b478f03ee2f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["# Importation des différentes librairies, classes et fonctions utilespour le notebook\n","\n","#Sickit learn met régulièrement à jour des versions et \n","#indique des futurs warnings. \n","#ces deux lignes permettent de ne pas les afficher.\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","\n","# librairies générales\n","import pandas as pd\n","import re\n","from tabulate import tabulate\n","import time\n","import numpy as np\n","import pickle\n","import string\n","import base64\n","import sys\n","\n","# librairie affichage\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# librairies scikit learn\n","import sklearn\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.base import TransformerMixin\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","\n","# librairies des classifiers utilisés\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# librairies NLTK\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import PorterStemmer \n","from nltk.corpus import stopwords\n","from nltk import word_tokenize \n","\n"," \n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","stop_words = set(stopwords.words('english')) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84i15_2X1Fr3"},"outputs":[],"source":["my_local_drive='/content/drive/MyDrive/ML/Prof/ML_FDS'\n","\n","# Ajout du path pour les librairies, fonctions et données\n","sys.path.append(my_local_drive)\n","# Se positionner sur le répertoire associé\n","#%cd $my_local_drive\n","\n","#%pwd\n","\n","# fonctions utilities (affichage, confusion, etc.)\n","from MyNLPUtilities import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0KqBSYJHdWHk"},"outputs":[],"source":["df_all = pd.concat([df_train,df_test])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1682784995720,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"oJohKa29qXg0","outputId":"9d1f1a32-4432-4f2a-f1b1-81b681cddf51"},"outputs":[{"output_type":"stream","name":"stdout","text":["public_id      612\n","text             0\n","title           23\n","our rating       0\n","ID            1264\n","dtype: int64\n"]}],"source":["# compter les valeurs manquantes dans chaque colonne\n","num_missing_values = df_all.isna().sum()\n","print(num_missing_values)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":229,"status":"ok","timestamp":1682785041299,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"sAuLr5smqXjE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a5cede1e-8c77-4b1a-e17c-de34ddc3a0df"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c7b19893d15a>:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_all['classe'] = df_all['our rating'].map({'true': 1, 'false': 2})\n"]}],"source":["df_all = df_all[~df_all['our rating'].isin(['mixture', 'other'])]\n","\n","df_all['classe'] = df_all['our rating'].map({'true': 1, 'false': 2})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228,"status":"ok","timestamp":1682785071847,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"nMqjhQt7Z9ZK","outputId":"a799ab0a-215d-4b9f-afd3-813bb1caaf17"},"outputs":[{"output_type":"stream","name":"stdout","text":["2    893\n","1    421\n","Name: classe, dtype: int64\n"]}],"source":["print(df_all[\"classe\"].value_counts())"]},{"cell_type":"markdown","source":["Equilibrage des classes"],"metadata":{"id":"DlCYiNVzzsqJ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":218,"status":"ok","timestamp":1682785087204,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"GtblP4J7kqJv","outputId":"e224a0cb-9b13-4ff5-f3cc-09d648641de6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Taille du jeu de données équilibré :  (842, 6)\n","2    421\n","1    421\n","Name: classe, dtype: int64\n"]}],"source":["from sklearn.utils import resample\n","import pandas as pd\n","\n","\n","\n","# Séparer les classes majoritaires et minoritaires\n","df_majority = df_all[df_all['classe'] == 2]\n","df_minority = df_all[df_all['classe'] == 1]\n","\n","# Sous-échantillonner la classe majoritaire\n","df_majority_downsampled = resample(df_majority, \n","                                   replace=False,    # Échantillonnage sans remplacement\n","                                   n_samples=len(df_minority), # Nombre d'échantillons égal à la classe minoritaire\n","                                   random_state=42)  # Pour la reproductibilité\n","\n","# Combiner les classes majoritaire et minoritaire\n","df_balanced = pd.concat([df_majority_downsampled, df_minority])\n","\n","# Afficher la taille du jeu de données équilibré\n","print(\"Taille du jeu de données équilibré : \", df_balanced.shape)\n","\n","df_all = df_balanced\n","print(df_all['classe'].value_counts())"]},{"cell_type":"markdown","metadata":{"id":"-jqEchizbBic"},"source":["Définition de la fonction  MyCleanText"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1682785006251,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"1l9cYobAbIjV","outputId":"d9eb9aad-ad81-4046-d2da-878244a3541e"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import re\n","import string\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import PorterStemmer\n","from nltk.corpus import stopwords\n","from nltk import word_tokenize\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","stop_words = set(stopwords.words('english'))\n","\n","def MyCleanText(X,\n"," lowercase=False, # mettre en minuscule\n"," removestopwords=False, # supprimer les stopwords\n"," removedigit=False, # supprimer les nombres\n"," getstemmer=False, # conserver la racine des termes\n"," getlemmatisation=False # lematisation des termes\n"," ):\n","    \n","    sentence = str(X)\n","    \n","    # suppression des caractères spéciaux\n","    sentence = re.sub(r'[^\\w\\s]',' ', sentence)\n","    \n","    # suppression de tous les caractères uniques\n","    sentence = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', sentence)\n","    \n","    # substitution des espaces multiples par un seul espace\n","    sentence = re.sub(r'\\s+', ' ', sentence, flags=re.I)\n","    \n","    # decoupage en mots\n","    tokens = word_tokenize(sentence)\n","    \n","    if lowercase:\n","        tokens = [token.lower() for token in tokens]\n","\n","    # suppression ponctuation\n","    table = str.maketrans('', '', string.punctuation)\n","    words = [token.translate(table) for token in tokens]\n","    \n","    # suppression des tokens non alphabetique ou numerique\n","    words = [word for word in words if word.isalnum()]\n","\n","    # suppression des tokens numerique\n","    if removedigit:\n","        words = [word for word in words if not word.isdigit()]\n","    \n","    # suppression des stopwords\n","    if removestopwords:\n","        words = [word for word in words if not word in stop_words]\n","    \n","    # lemmatisation\n","    if getlemmatisation:\n","        lemmatizer=WordNetLemmatizer()\n","        words = [lemmatizer.lemmatize(word)for word in words]\n","    \n","    # racinisation\n","    if getstemmer:\n","        ps = PorterStemmer()\n","        words=[ps.stem(word) for word in words]\n","\n","    sentence= ' '.join(words)\n","\n","    return sentence\n"]},{"cell_type":"markdown","metadata":{"id":"bfTRENa2dVLG"},"source":["Définition de la fonction TextNormalizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XT2JPRPGdaoM"},"outputs":[],"source":["from sklearn.base import BaseEstimator, TransformerMixin\n","class TextNormalizer(BaseEstimator, TransformerMixin):\n","    def __init__(self,\n","                 removestopwords=False, # suppression des stopwords\n","                 lowercase=False,# passage en minuscule\n","                 removedigit=False, # supprimer les nombres\n","                 getstemmer=False,# racinisation des termes\n","                 getlemmatisation=False # lemmatisation des termes\n","                ):\n","        self.lowercase=lowercase\n","        self.getstemmer=getstemmer\n","        self.removestopwords=removestopwords\n","        self.getlemmatisation=getlemmatisation\n","        self.removedigit=removedigit\n","    \n","    def transform(self, X, **transform_params):\n","        # Nettoyage du texte\n","        X=X.copy() # pour conserver le fichier d'origine\n","        return [MyCleanText(text, lowercase=self.lowercase,\n","                            getstemmer=self.getstemmer,\n","                            removestopwords=self.removestopwords,\n","                            getlemmatisation=self.getlemmatisation,\n","                            removedigit=self.removedigit) for text in X]\n","    \n","    def fit(self, X, y=None, **fit_params):\n","        return self\n","    \n","    def fit_transform(self, X, y=None, **fit_params):\n","        return self.fit(X).transform(X)\n","    \n","    def get_params(self, deep=True):\n","        return {\n","            'lowercase':self.lowercase,\n","            'getstemmer':self.getstemmer,\n","            'removestopwords':self.removestopwords,\n","            'getlemmatisation':self.getlemmatisation,\n","            'removedigit':self.removedigit\n","        }\n","    \n","    def set_params(self, **parameters):\n","        for parameter, value in parameters.items():\n","            setattr(self, parameter, value)\n","        return self\n"]},{"cell_type":"code","source":["!pip install -U spacy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hj4ZHzkk4zNZ","executionInfo":{"status":"ok","timestamp":1682785124994,"user_tz":-120,"elapsed":4558,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}},"outputId":"900ede24-cabb-406e-c164-20fcd3b65640"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n"]}]},{"cell_type":"code","source":["!pip install torch==1.10.1+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m0TWiEgf6PQ0","executionInfo":{"status":"ok","timestamp":1682785127632,"user_tz":-120,"elapsed":1326,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}},"outputId":"4aff1a24-647e-4e12-b665-2fb5015e358e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/cu111/torch_stable.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.10.1+cu111 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.10.1+cu111\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!python -m spacy download fr_core_news_sm\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ms64cmhb5SIy","executionInfo":{"status":"ok","timestamp":1682785152530,"user_tz":-120,"elapsed":24003,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}},"outputId":"a3f1f19e-b2c0-44f5-f7ed-55e5001f162c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-04-29 16:18:55.121013: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-29 16:18:57.008651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fr-core-news-sm==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.5.0/fr_core_news_sm-3.5.0-py3-none-any.whl (16.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.5.0) (3.5.2)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.10.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.0.12)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.10.7)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.27.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.7)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.0.4)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (6.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.0.8)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.3.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.0.9)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.4.6)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.1.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.65.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (67.7.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.22.4)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (8.1.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (23.1)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.7.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.8)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2022.12.7)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.1.2)\n","Installing collected packages: fr-core-news-sm\n","Successfully installed fr-core-news-sm-3.5.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_sm')\n"]}]},{"cell_type":"markdown","source":["Extraction des entités nommées à partir d'un corpus avec NLTK et ajout de features dans Pandas"],"metadata":{"id":"55TV-eZd0NPI"}},{"cell_type":"code","source":["import nltk\n","import pandas as pd\n","\n","# Télécharger les corpus et modèles nécessaires pour la reconnaissance d'entités nommées\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","\n","\n","\n","# Appliquer la reconnaissance d'entités nommées\n","entities = []\n","for text in df_all.text:\n","    tokens = nltk.word_tokenize(text)\n","    tagged = nltk.pos_tag(tokens)\n","    entities_list = []\n","    for chunk in nltk.ne_chunk(tagged):\n","        if hasattr(chunk, 'label'):\n","            entities_list.append(' '.join(c[0] for c in chunk))\n","    entities.append(entities_list)\n","\n","# Ajouter les entités extraites comme features\n","df_all['entities'] = entities\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pksl7Aa4OdY","executionInfo":{"status":"ok","timestamp":1682785493404,"user_tz":-120,"elapsed":194008,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}},"outputId":"b6679c06-47da-45e4-a706-055d8cbdbc3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]}]},{"cell_type":"code","source":["df_all.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"id":"QuUJiOsL-h6T","executionInfo":{"status":"ok","timestamp":1682785493406,"user_tz":-120,"elapsed":51,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}},"outputId":"a09f7b74-7d7d-41d7-ceb6-af8b78085d67"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     public_id                                               text  \\\n","186        NaN  During the predawn hours on New Year’s Day, De...   \n","833   f2fcb445  LONG-TERM MASK USE MAY CONTRIBUTE TO ADVANCED ...   \n","1010  8469a163  The Biden administration will soon deliver a s...   \n","200        NaN  As many as 45,000 people may have died from th...   \n","58    ae596f59  A Proof has recently appeared that cash attach...   \n","397   88477948  Now that it’s 2018, an election year, I would ...   \n","411   487c871b  Nation  President Boards E-4b Command Post; Fl...   \n","494   4905a5f5  The CO2 error is the root of the biggest scam ...   \n","285   dca71385  Sharon Stone smoking in Basic Instinct  Every ...   \n","180   0a7d532e  The Centers for Disease Control and Prevention...   \n","\n","                                                  title our rating  \\\n","186         Delta Force Raids Biden Compound in Ukraine      false   \n","833   FIRST CLASS Schools reopen with kids in masks ...      false   \n","1010                U.S. Senator Jeff Merkley of Oregon      false   \n","200   Top Cardiologist: Game-Changing Study Shows CO...      false   \n","58    The New York Times Affirms: ‘Soros & Clinton P...      false   \n","397   HEY LOOK! Senator Tammy Baldwin Is Back In Wis...      false   \n","411   President Boards E-4b Command Post; Flying to ...      false   \n","494   Tim Ball: The Evidence Proves That CO2 is Not ...      false   \n","285   SHOCKING REPORT: Smoking May Protect Lungs Fro...      false   \n","180   CDC Announces That Students May Be Kept From P...      false   \n","\n","                                           ID  classe  \\\n","186   105625103119574386858328487241855757744       2   \n","833                                       NaN       2   \n","1010                                      NaN       2   \n","200   200049446239665258541118918005789068501       2   \n","58                                        NaN       2   \n","397                                       NaN       2   \n","411                                       NaN       2   \n","494                                       NaN       2   \n","285                                       NaN       2   \n","180                                       NaN       2   \n","\n","                                               entities  \n","186   [New, Delta Force, Ukraine, Mariupol, White Ho...  \n","833                           [CONTRIBUTE, LUNG, STUDY]  \n","1010  [Biden, SolarWinds, Russia, Washington, US Nat...  \n","200   [mRNA, COVID, Peter McCullough, COVID, McCullo...  \n","58    [Hillary Clinton, George Soros, Trump, New Yor...  \n","397   [Tammy Baldwin, Wisconsin, Wisconsin, Almost, ...  \n","411   [Nation, Boards, Command Post, NMCC Abilene, T...  \n","494   [CO2, Sustainable, Intergovernmental Panel, Cl...  \n","285   [Sharon, Basic, Orwellian, American, American,...  \n","180   [Centers, Disease Control, Tell, CDC, Sham, Wa...  "],"text/html":["\n","  <div id=\"df-cb2234dc-acd2-43ca-a06e-4b793807220d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>public_id</th>\n","      <th>text</th>\n","      <th>title</th>\n","      <th>our rating</th>\n","      <th>ID</th>\n","      <th>classe</th>\n","      <th>entities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>186</th>\n","      <td>NaN</td>\n","      <td>During the predawn hours on New Year’s Day, De...</td>\n","      <td>Delta Force Raids Biden Compound in Ukraine</td>\n","      <td>false</td>\n","      <td>105625103119574386858328487241855757744</td>\n","      <td>2</td>\n","      <td>[New, Delta Force, Ukraine, Mariupol, White Ho...</td>\n","    </tr>\n","    <tr>\n","      <th>833</th>\n","      <td>f2fcb445</td>\n","      <td>LONG-TERM MASK USE MAY CONTRIBUTE TO ADVANCED ...</td>\n","      <td>FIRST CLASS Schools reopen with kids in masks ...</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>[CONTRIBUTE, LUNG, STUDY]</td>\n","    </tr>\n","    <tr>\n","      <th>1010</th>\n","      <td>8469a163</td>\n","      <td>The Biden administration will soon deliver a s...</td>\n","      <td>U.S. Senator Jeff Merkley of Oregon</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>[Biden, SolarWinds, Russia, Washington, US Nat...</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>NaN</td>\n","      <td>As many as 45,000 people may have died from th...</td>\n","      <td>Top Cardiologist: Game-Changing Study Shows CO...</td>\n","      <td>false</td>\n","      <td>200049446239665258541118918005789068501</td>\n","      <td>2</td>\n","      <td>[mRNA, COVID, Peter McCullough, COVID, McCullo...</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>ae596f59</td>\n","      <td>A Proof has recently appeared that cash attach...</td>\n","      <td>The New York Times Affirms: ‘Soros &amp; Clinton P...</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>[Hillary Clinton, George Soros, Trump, New Yor...</td>\n","    </tr>\n","    <tr>\n","      <th>397</th>\n","      <td>88477948</td>\n","      <td>Now that it’s 2018, an election year, I would ...</td>\n","      <td>HEY LOOK! Senator Tammy Baldwin Is Back In Wis...</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>[Tammy Baldwin, Wisconsin, Wisconsin, Almost, ...</td>\n","    </tr>\n","    <tr>\n","      <th>411</th>\n","      <td>487c871b</td>\n","      <td>Nation  President Boards E-4b Command Post; Fl...</td>\n","      <td>President Boards E-4b Command Post; Flying to ...</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>[Nation, Boards, Command Post, NMCC Abilene, T...</td>\n","    </tr>\n","    <tr>\n","      <th>494</th>\n","      <td>4905a5f5</td>\n","      <td>The CO2 error is the root of the biggest scam ...</td>\n","      <td>Tim Ball: The Evidence Proves That CO2 is Not ...</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>[CO2, Sustainable, Intergovernmental Panel, Cl...</td>\n","    </tr>\n","    <tr>\n","      <th>285</th>\n","      <td>dca71385</td>\n","      <td>Sharon Stone smoking in Basic Instinct  Every ...</td>\n","      <td>SHOCKING REPORT: Smoking May Protect Lungs Fro...</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>[Sharon, Basic, Orwellian, American, American,...</td>\n","    </tr>\n","    <tr>\n","      <th>180</th>\n","      <td>0a7d532e</td>\n","      <td>The Centers for Disease Control and Prevention...</td>\n","      <td>CDC Announces That Students May Be Kept From P...</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>[Centers, Disease Control, Tell, CDC, Sham, Wa...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb2234dc-acd2-43ca-a06e-4b793807220d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cb2234dc-acd2-43ca-a06e-4b793807220d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cb2234dc-acd2-43ca-a06e-4b793807220d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["Corrélation entre la présence d'entités nommées dans les articles et la véracité des informations qu'ils contiennent"],"metadata":{"id":"ODRp4zo00zh5"}},{"cell_type":"code","source":["# Sélectionner uniquement les lignes avec des fake news\n","df_fake = df_all[df_all['classe'] == 2]\n","\n","# Transformer la colonne entities en une colonne avec une entité par ligne\n","df_fake_exploded = df_fake.explode('entities')\n","\n","# Compter le nombre de fake news pour chaque entité\n","fake_news_count = df_fake_exploded.groupby('entities')['classe'].count().sort_values(ascending=False)\n","\n","# Afficher les résultats\n","print(fake_news_count)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OeejjIMjgxw1","executionInfo":{"status":"ok","timestamp":1682785493408,"user_tz":-120,"elapsed":18,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}},"outputId":"f9fb3a92-5b99-4bc9-d272-5fc04bc9b321"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["entities\n","Trump              397\n","China              238\n","U.S.               184\n","American           163\n","US                 144\n","                  ... \n","Huawei Cloud         1\n","Hubei                1\n","Hubei Institute      1\n","Hull                 1\n","Koran                1\n","Name: classe, Length: 5973, dtype: int64\n"]}]},{"cell_type":"markdown","source":["Classification de la véracité des informations à partir d'un corpus contenant des entités nommées en utilisant une SVM et la vectorisation TF-IDF"],"metadata":{"id":"JQdIaLKR1GbM"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import SVC\n","import pandas as pd\n","\n","# Define the pipeline\n","pipe = Pipeline([\n","    (\"cleaner\", TextNormalizer(removestopwords=True, lowercase=True, removedigit=True, getstemmer=False, getlemmatisation=False)),\n","    (\"TfidfVectorizer\", TfidfVectorizer()), \n","    (\"svm\", SVC(C=1, gamma=0.001, kernel='linear'))\n","])\n","\n","\n","\n","X = []\n","for entities in df_all.entities:\n","    X.append(' '.join(entities))\n","y = df_all['classe']\n","\n","\n","# diviser les données en ensembles d'entraînement et de test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# ajuster le pipeline sur les données d'entraînement\n","pipe.fit(X_train, y_train)\n","\n","\n","from sklearn.metrics import accuracy_score\n","\n","# prédire les étiquettes de classe sur l'ensemble de données de test\n","\n","y_true, y_pred = y_test, pipe.predict(X_test)\n","\n","print(classification_report(y_true, y_pred))\n","\n","# calculer la précision en comparant les prédictions avec les étiquettes de classe réelles\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# afficher la précision\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjTlpLQh_A4B","executionInfo":{"status":"ok","timestamp":1682787981716,"user_tz":-120,"elapsed":552,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}},"outputId":"0c9adbc1-2da0-42f3-9b6b-e8bb886859cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           1       0.73      0.78      0.75        85\n","           2       0.76      0.70      0.73        84\n","\n","    accuracy                           0.74       169\n","   macro avg       0.74      0.74      0.74       169\n","weighted avg       0.74      0.74      0.74       169\n","\n","Accuracy: 0.7396449704142012\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}