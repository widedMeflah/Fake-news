{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29887,"status":"ok","timestamp":1682705960477,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"gUCys6jddVC8","outputId":"006d7019-31da-4a2f-afc4-0d030a9b2a95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tXK6a-dIiqAj"},"outputs":[],"source":["import pandas as pd\n","df_train = pd.read_csv('/content/drive/MyDrive/ML/HAI817_Projet_train.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/ML/HAI817_Projet_test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2297,"status":"ok","timestamp":1682705964326,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"RF6BiAf21qW6","outputId":"d6c40528-ad68-41b2-ed78-d349e6039c11"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["# Importation des différentes librairies, classes et fonctions utilespour le notebook\n","\n","#Sickit learn met régulièrement à jour des versions et \n","#indique des futurs warnings. \n","#ces deux lignes permettent de ne pas les afficher.\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","\n","# librairies générales\n","import pandas as pd\n","import re\n","from tabulate import tabulate\n","import time\n","import numpy as np\n","import pickle\n","import string\n","import base64\n","import sys\n","\n","# librairie affichage\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# librairies scikit learn\n","import sklearn\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.base import TransformerMixin\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","\n","# librairies des classifiers utilisés\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# librairies NLTK\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import PorterStemmer \n","from nltk.corpus import stopwords\n","from nltk import word_tokenize \n","\n"," \n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","stop_words = set(stopwords.words('english')) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84i15_2X1Fr3"},"outputs":[],"source":["my_local_drive='/content/drive/MyDrive/ML/Prof/ML_FDS'\n","\n","# Ajout du path pour les librairies, fonctions et données\n","sys.path.append(my_local_drive)\n","# Se positionner sur le répertoire associé\n","#%cd $my_local_drive\n","\n","#%pwd\n","\n","# fonctions utilities (affichage, confusion, etc.)\n","from MyNLPUtilities import *"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":237,"status":"ok","timestamp":1682718677252,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"0KqBSYJHdWHk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"22379cd7-a38e-470b-f05e-c880137299ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1876, 5)\n"]}],"source":["df_all = pd.concat([df_train,df_test])\n","print(df_all.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1682705980360,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"oJohKa29qXg0","outputId":"8ca86921-c8a2-4c45-971a-b0e8817224fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["public_id      612\n","text             0\n","title           23\n","our rating       0\n","ID            1264\n","dtype: int64\n"]}],"source":["# compter les valeurs manquantes dans chaque colonne\n","num_missing_values = df_all.isna().sum()\n","print(num_missing_values)"]},{"cell_type":"markdown","metadata":{"id":"RQBLyZjLbXr-"},"source":["Encodage des classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sAuLr5smqXjE"},"outputs":[],"source":["\n","\n","df_all['classe'] = df_all['our rating'].map({'true': 1, 'false': 2, 'mixture': 3, 'other': 4})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1682705992393,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"nMqjhQt7Z9ZK","outputId":"74de2fa6-25b0-4975-f697-76f6be7bcb5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["2    893\n","1    421\n","3    414\n","4    148\n","Name: classe, dtype: int64\n"]}],"source":["print(df_all[\"classe\"].value_counts())"]},{"cell_type":"markdown","metadata":{"id":"pd9muhiYbn6J"},"source":["Equilibrage des classes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682705993517,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"GtblP4J7kqJv","outputId":"bfa210c4-28b2-4b3e-c00f-888c801fa15a"},"outputs":[{"output_type":"stream","name":"stdout","text":["false      250\n","true       250\n","mixture    250\n","other      250\n","Name: our rating, dtype: int64\n"]}],"source":["from sklearn.utils import resample\n","import pandas as pd\n","\n","# Downsampling de la classe majoritaire\n","false_downsampled = resample(df_all[df_all['our rating'] == 'false'], replace=False, n_samples=250, random_state=42)\n","\n","# Upsampling de la classe minoritaire\n","true_upsampled = resample(df_all[df_all['our rating'] == 'true'], replace=False, n_samples=250, random_state=42)\n","mixture_upsampled = resample(df_all[df_all['our rating'] == 'mixture'], replace=False, n_samples=250, random_state=42)\n","other_upsampled = resample(df_all[df_all['our rating'] == 'other'], replace=True, n_samples=250, random_state=42)\n","\n","# Concaténer les données échantillonnées\n","balanced_data = pd.concat([false_downsampled, true_upsampled, mixture_upsampled, other_upsampled])\n","\n","# Afficher les nouvelles proportions des classes\n","df_all = balanced_data\n","print(df_all['our rating'].value_counts())\n"]},{"cell_type":"markdown","metadata":{"id":"-jqEchizbBic"},"source":["Définition de la fonction  MyCleanText"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682705999260,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"1l9cYobAbIjV","outputId":"10802272-8cb9-46fe-86d7-143c56ea641c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import re\n","import string\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import PorterStemmer\n","from nltk.corpus import stopwords\n","from nltk import word_tokenize\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","stop_words = set(stopwords.words('english'))\n","\n","def MyCleanText(X,\n"," lowercase=False, # mettre en minuscule\n"," removestopwords=False, # supprimer les stopwords\n"," removedigit=False, # supprimer les nombres\n"," getstemmer=False, # conserver la racine des termes\n"," getlemmatisation=False # lematisation des termes\n"," ):\n","    \n","    sentence = str(X)\n","    \n","    # suppression des caractères spéciaux\n","    sentence = re.sub(r'[^\\w\\s]',' ', sentence)\n","    \n","    # suppression de tous les caractères uniques\n","    sentence = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', sentence)\n","    \n","    # substitution des espaces multiples par un seul espace\n","    sentence = re.sub(r'\\s+', ' ', sentence, flags=re.I)\n","    \n","    # decoupage en mots\n","    tokens = word_tokenize(sentence)\n","    \n","    if lowercase:\n","        tokens = [token.lower() for token in tokens]\n","\n","    # suppression ponctuation\n","    table = str.maketrans('', '', string.punctuation)\n","    words = [token.translate(table) for token in tokens]\n","    \n","    # suppression des tokens non alphabetique ou numerique\n","    words = [word for word in words if word.isalnum()]\n","\n","    # suppression des tokens numerique\n","    if removedigit:\n","        words = [word for word in words if not word.isdigit()]\n","    \n","    # suppression des stopwords\n","    if removestopwords:\n","        words = [word for word in words if not word in stop_words]\n","    \n","    # lemmatisation\n","    if getlemmatisation:\n","        lemmatizer=WordNetLemmatizer()\n","        words = [lemmatizer.lemmatize(word)for word in words]\n","    \n","    # racinisation\n","    if getstemmer:\n","        ps = PorterStemmer()\n","        words=[ps.stem(word) for word in words]\n","\n","    sentence= ' '.join(words)\n","\n","    return sentence\n"]},{"cell_type":"markdown","metadata":{"id":"bfTRENa2dVLG"},"source":["Définition de la fonction TextNormalizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XT2JPRPGdaoM"},"outputs":[],"source":["from sklearn.base import BaseEstimator, TransformerMixin\n","class TextNormalizer(BaseEstimator, TransformerMixin):\n","    def __init__(self,\n","                 removestopwords=False, # suppression des stopwords\n","                 lowercase=False,# passage en minuscule\n","                 removedigit=False, # supprimer les nombres\n","                 getstemmer=False,# racinisation des termes\n","                 getlemmatisation=False # lemmatisation des termes\n","                ):\n","        self.lowercase=lowercase\n","        self.getstemmer=getstemmer\n","        self.removestopwords=removestopwords\n","        self.getlemmatisation=getlemmatisation\n","        self.removedigit=removedigit\n","    \n","    def transform(self, X, **transform_params):\n","        # Nettoyage du texte\n","        X=X.copy() # pour conserver le fichier d'origine\n","        return [MyCleanText(text, lowercase=self.lowercase,\n","                            getstemmer=self.getstemmer,\n","                            removestopwords=self.removestopwords,\n","                            getlemmatisation=self.getlemmatisation,\n","                            removedigit=self.removedigit) for text in X]\n","    \n","    def fit(self, X, y=None, **fit_params):\n","        return self\n","    \n","    def fit_transform(self, X, y=None, **fit_params):\n","        return self.fit(X).transform(X)\n","    \n","    def get_params(self, deep=True):\n","        return {\n","            'lowercase':self.lowercase,\n","            'getstemmer':self.getstemmer,\n","            'removestopwords':self.removestopwords,\n","            'getlemmatisation':self.getlemmatisation,\n","            'removedigit':self.removedigit\n","        }\n","    \n","    def set_params(self, **parameters):\n","        for parameter, value in parameters.items():\n","            setattr(self, parameter, value)\n","        return self\n"]},{"cell_type":"markdown","metadata":{"id":"83kbMFhF0HWD"},"source":["## **Evaluation de différents classifieurs**  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ngrFhYZY0Q-O"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# creation du tableau des différents classifieur \n","\n","\n","models = []\n","models.append(('MultinomialNB',MultinomialNB()))\n","models.append(('LR', LogisticRegression(solver='lbfgs')))\n","models.append(('KNN', KNeighborsClassifier()))\n","models.append(('CART', DecisionTreeClassifier()))\n","models.append(('RF', RandomForestClassifier()))\n","models.append(('SVM', SVC()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i_D1hV7m8C1e"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","import time\n"]},{"cell_type":"markdown","metadata":{"id":"rJMykTdGEKMc"},"source":["removestopwords=False, # suppression des stopwords\n","\n","lowercase=False,# passage en minuscule\n","\n","removedigit=False, # supprimer les nombres\n","\n","getstemmer=False,# racinisation des termes\n","\n","getlemmatisation=False # lemmatisation des termes"]},{"cell_type":"markdown","metadata":{"id":"tODHuGQDPf7g"},"source":["**Choix du meilleur classifieur avec les meilleurs parametres de prétraitement** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Fl_Vat3L5jr"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from sklearn.model_selection import cross_val_score, KFold, cross_val_predict\n","from sklearn.metrics import classification_report\n","import numpy as np\n","\n","class Result:\n","    def __init__(self, name, score_accuracy, score_precision, score_rappel, score_mesure, temps, conf_mat):\n","        self.name = name\n","        self.score_accuracy = score_accuracy\n","        self.score_precision = score_precision\n","        self.score_rappel = score_rappel\n","        self.score_mesure = score_mesure\n","        self.temps = temps\n","        self.conf_mat = conf_mat \n","\n","def ma_fonction(removestopwords1, lowercase1, removedigit1, getstemmer1, getlemmatisation1):\n","\n","    score_accuracy = 'accuracy'\n","    score_precision = 'precision_macro'\n","    score_rappel = 'recall_macro'\n","    score_mesure = 'f1_macro'\n","    seed = 7        \n","    allresults = []\n","    results = []\n","    names = []\n","\n","    X = df_all['text']\n","    y = df_all['classe']\n","\n","    # Nous appliquons les pré-traitements sur X\n","\n","    text_normalizer = TextNormalizer(removestopwords=removestopwords1, lowercase=lowercase1, removedigit=removedigit1, getstemmer=getstemmer1, getlemmatisation=getlemmatisation1)  \n","    # appliquer fit.transform pour réaliser les pré-traitements sur X\n","    X_cleaned = text_normalizer.fit_transform(X)\n","\n","    # pour l'enchainer avec un tf-idf et obtenir une matrice\n","    tfidf = TfidfVectorizer()\n","    features = tfidf.fit_transform(X_cleaned).toarray()\n","\n","    # attention ici il faut passer features dans cross_val_score plutôt que X\n","\n","    for name, model in models:\n","        # cross validation en 10 fois\n","        kfold = KFold(n_splits=10, random_state=seed, shuffle=True)\n","\n","        print(\"Evaluation de\", name)\n","        start_time = time.time()\n","        # application de la classification\n","        cv_results = cross_val_score(model, features, y, cv=kfold, scoring=score_accuracy)\n","        cv_results_precision = cross_val_score(model, features, y, cv=kfold, scoring=score_precision)\n","        cv_results_rappel = cross_val_score(model, features, y, cv=kfold, scoring=score_rappel)\n","        cv_results_mesure = cross_val_score(model, features, y, cv=kfold, scoring=score_mesure)\n","\n","        # Calculer la matrice de confusion\n","        y_pred = cross_val_predict(model, features, y, cv=kfold)\n","        conf_mat = confusion_matrix(y, y_pred, labels=np.unique(y))\n","\n","        # Affichage du rapport de classification\n","        class_names = np.unique(y)\n","        print(\"Classification Report:\")\n","       \n","\n","        print(classification_report(y, y_pred, labels=class_names))\n","\n","        # Affichage de la matrice de confusion\n","        print(\"Confusion Matrix:\")\n","        print(conf_mat)\n","\n","        thetime = time.time() - start_time\n","\n","       \n","\n","        result = Result(name, cv_results.mean(), cv_results_precision.mean(), cv_results_rappel.mean(), cv_results_mesure.mean(), thetime, conf_mat)\n","        results.append(cv_results)\n","        names.append(name)\n","        print(\"%s : exactitude=%.3f, précision=%.3f, rappel=%.3f, mesure F1=%.3f in temps d'exécution=%.3f s\" % (name, cv_results.mean(), cv_results_precision.mean(), cv_results_rappel.mean(), cv_results_mesure.mean(), thetime))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1575428,"status":"ok","timestamp":1682637417560,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"2llfXoZTOQUn","outputId":"7127c083-4309-4d11-952c-ed5010845c01"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation de MultinomialNB\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.42      0.64      0.51       250\n","           2       0.66      0.46      0.54       250\n","           3       0.44      0.36      0.39       250\n","           4       0.79      0.74      0.77       250\n","\n","    accuracy                           0.55      1000\n","   macro avg       0.58      0.55      0.55      1000\n","weighted avg       0.58      0.55      0.55      1000\n","\n","Confusion Matrix:\n","[[161  28  51  10]\n"," [ 71 116  44  19]\n"," [118  23  89  20]\n"," [ 35  10  19 186]]\n","MultinomialNB : exactitude=0.552, précision=0.591, rappel=0.560, mesure F1=0.552 in temps d'exécution=7.286 s\n","Evaluation de LR\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.51      0.46      0.49       250\n","           2       0.58      0.61      0.59       250\n","           3       0.48      0.51      0.49       250\n","           4       0.84      0.81      0.82       250\n","\n","    accuracy                           0.60      1000\n","   macro avg       0.60      0.60      0.60      1000\n","weighted avg       0.60      0.60      0.60      1000\n","\n","Confusion Matrix:\n","[[116  49  72  13]\n"," [ 34 153  51  12]\n"," [ 64  45 127  14]\n"," [ 13  18  17 202]]\n","LR : exactitude=0.598, précision=0.606, rappel=0.601, mesure F1=0.598 in temps d'exécution=389.590 s\n","Evaluation de KNN\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.36      0.53      0.43       250\n","           2       0.49      0.38      0.43       250\n","           3       0.38      0.28      0.32       250\n","           4       0.63      0.66      0.64       250\n","\n","    accuracy                           0.46      1000\n","   macro avg       0.47      0.46      0.46      1000\n","weighted avg       0.47      0.46      0.46      1000\n","\n","Confusion Matrix:\n","[[132  34  52  32]\n"," [ 87  95  41  27]\n"," [ 97  45  69  39]\n"," [ 48  19  18 165]]\n","KNN : exactitude=0.461, précision=0.471, rappel=0.464, mesure F1=0.455 in temps d'exécution=15.686 s\n","Evaluation de CART\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.43      0.42      0.42       250\n","           2       0.48      0.40      0.43       250\n","           3       0.41      0.42      0.42       250\n","           4       0.71      0.84      0.77       250\n","\n","    accuracy                           0.52      1000\n","   macro avg       0.51      0.52      0.51      1000\n","weighted avg       0.51      0.52      0.51      1000\n","\n","Confusion Matrix:\n","[[104  43  74  29]\n"," [ 57 100  59  34]\n"," [ 66  56 104  24]\n"," [ 14  11  14 211]]\n","CART : exactitude=0.513, précision=0.499, rappel=0.511, mesure F1=0.490 in temps d'exécution=124.651 s\n","Evaluation de RF\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.54      0.56      0.55       250\n","           2       0.55      0.59      0.57       250\n","           3       0.49      0.50      0.50       250\n","           4       0.97      0.84      0.90       250\n","\n","    accuracy                           0.62      1000\n","   macro avg       0.64      0.62      0.63      1000\n","weighted avg       0.64      0.62      0.63      1000\n","\n","Confusion Matrix:\n","[[139  50  60   1]\n"," [ 44 148  56   2]\n"," [ 62  59 126   3]\n"," [ 12  12  15 211]]\n","RF : exactitude=0.620, précision=0.661, rappel=0.623, mesure F1=0.647 in temps d'exécution=147.561 s\n","Evaluation de SVM\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.53      0.45      0.48       250\n","           2       0.55      0.60      0.57       250\n","           3       0.49      0.58      0.53       250\n","           4       0.97      0.83      0.90       250\n","\n","    accuracy                           0.61      1000\n","   macro avg       0.63      0.61      0.62      1000\n","weighted avg       0.63      0.61      0.62      1000\n","\n","Confusion Matrix:\n","[[112  55  81   2]\n"," [ 37 149  62   2]\n"," [ 49  53 146   2]\n"," [ 15  16  11 208]]\n","SVM : exactitude=0.615, précision=0.636, rappel=0.619, mesure F1=0.619 in temps d'exécution=873.698 s\n"]}],"source":["#removestopwords, lowercase, removedigit, getstemmer,getlemmatisation\n","ma_fonction(True, True, True, True, True)"]},{"cell_type":"markdown","metadata":{"id":"TiiKChahBZKm"},"source":["D'après les résultats affichés, le meilleur classifieur est SVM \n","SVM a obtenu un score élevé de précision, de rappel et de mesure F1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2191686,"status":"ok","timestamp":1682639609241,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"},"user_tz":-120},"id":"fofdbiYVPJ0P","outputId":"c8e569db-f5bc-4d56-b56b-8200ec8dac5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation de MultinomialNB\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.43      0.66      0.52       250\n","           2       0.67      0.49      0.56       250\n","           3       0.49      0.37      0.42       250\n","           4       0.81      0.78      0.80       250\n","\n","    accuracy                           0.57      1000\n","   macro avg       0.60      0.57      0.57      1000\n","weighted avg       0.60      0.57      0.57      1000\n","\n","Confusion Matrix:\n","[[166  28  45  11]\n"," [ 72 122  38  18]\n"," [121  21  92  16]\n"," [ 29  12  14 195]]\n","MultinomialNB : exactitude=0.575, précision=0.608, rappel=0.581, mesure F1=0.573 in temps d'exécution=12.158 s\n","Evaluation de LR\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.53      0.49      0.51       250\n","           2       0.58      0.62      0.60       250\n","           3       0.51      0.54      0.52       250\n","           4       0.86      0.80      0.83       250\n","\n","    accuracy                           0.61      1000\n","   macro avg       0.62      0.61      0.62      1000\n","weighted avg       0.62      0.61      0.62      1000\n","\n","Confusion Matrix:\n","[[123  47  69  11]\n"," [ 34 155  49  12]\n"," [ 59  47 135   9]\n"," [ 16  19  14 201]]\n","LR : exactitude=0.614, précision=0.624, rappel=0.616, mesure F1=0.613 in temps d'exécution=551.317 s\n","Evaluation de KNN\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.38      0.52      0.44       250\n","           2       0.51      0.44      0.47       250\n","           3       0.41      0.30      0.35       250\n","           4       0.61      0.63      0.62       250\n","\n","    accuracy                           0.48      1000\n","   macro avg       0.48      0.47      0.47      1000\n","weighted avg       0.48      0.47      0.47      1000\n","\n","Confusion Matrix:\n","[[131  35  51  33]\n"," [ 73 110  35  32]\n"," [ 91  45  76  38]\n"," [ 46  24  22 158]]\n","KNN : exactitude=0.475, précision=0.480, rappel=0.475, mesure F1=0.468 in temps d'exécution=20.769 s\n","Evaluation de CART\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.42      0.43      0.42       250\n","           2       0.46      0.40      0.42       250\n","           3       0.43      0.41      0.42       250\n","           4       0.74      0.85      0.79       250\n","\n","    accuracy                           0.52      1000\n","   macro avg       0.51      0.52      0.51      1000\n","weighted avg       0.51      0.52      0.51      1000\n","\n","Confusion Matrix:\n","[[107  53  65  25]\n"," [ 63  99  59  29]\n"," [ 71  55 103  21]\n"," [ 15  10  12 213]]\n","CART : exactitude=0.540, précision=0.530, rappel=0.541, mesure F1=0.520 in temps d'exécution=199.800 s\n","Evaluation de RF\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.52      0.52      0.52       250\n","           2       0.56      0.60      0.58       250\n","           3       0.49      0.52      0.50       250\n","           4       0.94      0.84      0.89       250\n","\n","    accuracy                           0.62      1000\n","   macro avg       0.63      0.62      0.62      1000\n","weighted avg       0.63      0.62      0.62      1000\n","\n","Confusion Matrix:\n","[[130  47  66   7]\n"," [ 48 150  50   2]\n"," [ 63  54 129   4]\n"," [ 10  15  16 209]]\n","RF : exactitude=0.628, précision=0.646, rappel=0.623, mesure F1=0.616 in temps d'exécution=176.892 s\n","Evaluation de SVM\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.55      0.46      0.50       250\n","           2       0.58      0.61      0.59       250\n","           3       0.51      0.63      0.56       250\n","           4       0.98      0.83      0.90       250\n","\n","    accuracy                           0.63      1000\n","   macro avg       0.65      0.63      0.64      1000\n","weighted avg       0.65      0.63      0.64      1000\n","\n","Confusion Matrix:\n","[[115  51  83   1]\n"," [ 36 153  60   1]\n"," [ 45  45 158   2]\n"," [ 15  16  11 208]]\n","SVM : exactitude=0.634, précision=0.658, rappel=0.639, mesure F1=0.637 in temps d'exécution=1226.351 s\n"]}],"source":["ma_fonction(True, True, True, False, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"hLA-laXAqzgt","outputId":"3466f257-7b88-4a1f-9546-0f1d4144c48c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation de MultinomialNB\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.42      0.64      0.51       250\n","           2       0.66      0.48      0.55       250\n","           3       0.44      0.36      0.40       250\n","           4       0.79      0.74      0.77       250\n","\n","    accuracy                           0.56      1000\n","   macro avg       0.58      0.56      0.56      1000\n","weighted avg       0.58      0.56      0.56      1000\n","\n","Confusion Matrix:\n","[[161  28  51  10]\n"," [ 70 119  43  18]\n"," [117  23  90  20]\n"," [ 35  10  19 186]]\n","MultinomialNB : exactitude=0.556, précision=0.595, rappel=0.564, mesure F1=0.557 in temps d'exécution=6.375 s\n","Evaluation de LR\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.51      0.46      0.49       250\n","           2       0.57      0.62      0.60       250\n","           3       0.48      0.51      0.50       250\n","           4       0.84      0.80      0.82       250\n","\n","    accuracy                           0.60      1000\n","   macro avg       0.60      0.60      0.60      1000\n","weighted avg       0.60      0.60      0.60      1000\n","\n","Confusion Matrix:\n","[[116  50  71  13]\n"," [ 33 155  50  12]\n"," [ 64  46 127  13]\n"," [ 15  19  15 201]]\n","LR : exactitude=0.599, précision=0.607, rappel=0.602, mesure F1=0.598 in temps d'exécution=426.770 s\n","Evaluation de KNN\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.36      0.52      0.42       250\n","           2       0.50      0.39      0.44       250\n","           3       0.39      0.29      0.33       250\n","           4       0.63      0.66      0.64       250\n","\n","    accuracy                           0.46      1000\n","   macro avg       0.47      0.46      0.46      1000\n","weighted avg       0.47      0.46      0.46      1000\n","\n","Confusion Matrix:\n","[[129  36  52  33]\n"," [ 84  97  43  26]\n"," [ 97  44  72  37]\n"," [ 49  18  19 164]]\n","KNN : exactitude=0.462, précision=0.472, rappel=0.465, mesure F1=0.458 in temps d'exécution=16.428 s\n","Evaluation de CART\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.43      0.38      0.40       250\n","           2       0.44      0.43      0.44       250\n","           3       0.44      0.39      0.41       250\n","           4       0.67      0.84      0.75       250\n","\n","    accuracy                           0.51      1000\n","   macro avg       0.50      0.51      0.50      1000\n","weighted avg       0.50      0.51      0.50      1000\n","\n","Confusion Matrix:\n","[[ 96  58  64  32]\n"," [ 50 108  49  43]\n"," [ 65  61  97  27]\n"," [ 14  17   8 211]]\n","CART : exactitude=0.505, précision=0.493, rappel=0.517, mesure F1=0.494 in temps d'exécution=131.791 s\n","Evaluation de RF\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.53      0.54      0.53       250\n","           2       0.56      0.60      0.58       250\n","           3       0.48      0.51      0.49       250\n","           4       0.97      0.84      0.90       250\n","\n","    accuracy                           0.62      1000\n","   macro avg       0.63      0.62      0.63      1000\n","weighted avg       0.63      0.62      0.63      1000\n","\n","Confusion Matrix:\n","[[134  42  72   2]\n"," [ 45 149  54   2]\n"," [ 64  56 127   3]\n"," [ 11  19  11 209]]\n","RF : exactitude=0.626, précision=0.653, rappel=0.624, mesure F1=0.625 in temps d'exécution=147.082 s\n","Evaluation de SVM\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.53      0.45      0.49       250\n","           2       0.54      0.59      0.57       250\n","           3       0.49      0.59      0.53       250\n","           4       0.97      0.83      0.90       250\n","\n","    accuracy                           0.61      1000\n","   macro avg       0.63      0.61      0.62      1000\n","weighted avg       0.63      0.61      0.62      1000\n","\n","Confusion Matrix:\n","[[112  55  81   2]\n"," [ 37 148  63   2]\n"," [ 47  54 147   2]\n"," [ 15  16  11 208]]\n","SVM : exactitude=0.615, précision=0.637, rappel=0.620, mesure F1=0.619 in temps d'exécution=884.649 s\n"]}],"source":["ma_fonction(True, True, True, True, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Vs2jWbwoqzkI","outputId":"732ba507-2825-449b-df1d-a321748007d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation de MultinomialNB\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.42      0.65      0.51       250\n","           2       0.68      0.48      0.56       250\n","           3       0.44      0.36      0.40       250\n","           4       0.80      0.74      0.77       250\n","\n","    accuracy                           0.56      1000\n","   macro avg       0.59      0.56      0.56      1000\n","weighted avg       0.59      0.56      0.56      1000\n","\n","Confusion Matrix:\n","[[163  25  51  11]\n"," [ 70 119  44  17]\n"," [121  21  90  18]\n"," [ 36  10  18 186]]\n","MultinomialNB : exactitude=0.558, précision=0.600, rappel=0.566, mesure F1=0.559 in temps d'exécution=7.055 s\n","Evaluation de LR\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.52      0.47      0.49       250\n","           2       0.57      0.62      0.59       250\n","           3       0.48      0.52      0.50       250\n","           4       0.84      0.80      0.82       250\n","\n","    accuracy                           0.60      1000\n","   macro avg       0.60      0.60      0.60      1000\n","weighted avg       0.60      0.60      0.60      1000\n","\n","Confusion Matrix:\n","[[117  49  72  12]\n"," [ 34 154  50  12]\n"," [ 64  44 129  13]\n"," [ 12  21  17 200]]\n","LR : exactitude=0.600, précision=0.610, rappel=0.603, mesure F1=0.600 in temps d'exécution=432.993 s\n","Evaluation de KNN\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.36      0.52      0.43       250\n","           2       0.48      0.38      0.42       250\n","           3       0.39      0.28      0.33       250\n","           4       0.62      0.66      0.64       250\n","\n","    accuracy                           0.46      1000\n","   macro avg       0.46      0.46      0.45      1000\n","weighted avg       0.46      0.46      0.45      1000\n","\n","Confusion Matrix:\n","[[129  35  52  34]\n"," [ 88  94  40  28]\n"," [ 94  45  71  40]\n"," [ 46  22  18 164]]\n","KNN : exactitude=0.458, précision=0.468, rappel=0.461, mesure F1=0.452 in temps d'exécution=15.142 s\n","Evaluation de CART\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.49      0.44      0.46       250\n","           2       0.43      0.36      0.39       250\n","           3       0.46      0.45      0.46       250\n","           4       0.67      0.84      0.74       250\n","\n","    accuracy                           0.53      1000\n","   macro avg       0.51      0.53      0.51      1000\n","weighted avg       0.51      0.53      0.51      1000\n","\n","Confusion Matrix:\n","[[110  50  61  29]\n"," [ 56  91  56  47]\n"," [ 52  55 113  30]\n"," [  6  17  16 211]]\n","CART : exactitude=0.530, précision=0.525, rappel=0.523, mesure F1=0.520 in temps d'exécution=129.711 s\n","Evaluation de RF\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.54      0.56      0.55       250\n","           2       0.56      0.56      0.56       250\n","           3       0.48      0.54      0.51       250\n","           4       0.98      0.83      0.90       250\n","\n","    accuracy                           0.62      1000\n","   macro avg       0.64      0.62      0.63      1000\n","weighted avg       0.64      0.62      0.63      1000\n","\n","Confusion Matrix:\n","[[139  42  69   0]\n"," [ 46 140  62   2]\n"," [ 58  55 134   3]\n"," [ 13  15  14 208]]\n","RF : exactitude=0.610, précision=0.647, rappel=0.613, mesure F1=0.626 in temps d'exécution=132.657 s\n","Evaluation de SVM\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.54      0.45      0.49       250\n","           2       0.54      0.60      0.57       250\n","           3       0.49      0.59      0.53       250\n","           4       0.97      0.83      0.90       250\n","\n","    accuracy                           0.62      1000\n","   macro avg       0.63      0.62      0.62      1000\n","weighted avg       0.63      0.62      0.62      1000\n","\n","Confusion Matrix:\n","[[113  55  80   2]\n"," [ 36 149  63   2]\n"," [ 47  54 147   2]\n"," [ 15  16  11 208]]\n","SVM : exactitude=0.617, précision=0.640, rappel=0.623, mesure F1=0.622 in temps d'exécution=849.491 s\n"]}],"source":["ma_fonction(True, True, False, True, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"c9taKylYqznl","outputId":"f4c1f808-9abd-4ed9-9e05-01f1241b2f01"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation de MultinomialNB\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.42      0.65      0.51       250\n","           2       0.68      0.47      0.55       250\n","           3       0.44      0.36      0.39       250\n","           4       0.80      0.74      0.77       250\n","\n","    accuracy                           0.56      1000\n","   macro avg       0.58      0.55      0.56      1000\n","weighted avg       0.58      0.56      0.56      1000\n","\n","Confusion Matrix:\n","[[163  25  51  11]\n"," [ 71 117  44  18]\n"," [122  21  89  18]\n"," [ 36  10  18 186]]\n","MultinomialNB : exactitude=0.555, précision=0.598, rappel=0.563, mesure F1=0.556 in temps d'exécution=7.609 s\n","Evaluation de LR\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.50      0.46      0.48       250\n","           2       0.57      0.60      0.58       250\n","           3       0.48      0.52      0.50       250\n","           4       0.84      0.80      0.82       250\n","\n","    accuracy                           0.59      1000\n","   macro avg       0.60      0.59      0.59      1000\n","weighted avg       0.60      0.59      0.59      1000\n","\n","Confusion Matrix:\n","[[114  50  74  12]\n"," [ 37 150  51  12]\n"," [ 63  44 129  14]\n"," [ 12  20  17 201]]\n","LR : exactitude=0.594, précision=0.603, rappel=0.597, mesure F1=0.594 in temps d'exécution=427.276 s\n","Evaluation de KNN\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.37      0.53      0.43       250\n","           2       0.48      0.37      0.42       250\n","           3       0.39      0.28      0.32       250\n","           4       0.62      0.66      0.64       250\n","\n","    accuracy                           0.46      1000\n","   macro avg       0.46      0.46      0.45      1000\n","weighted avg       0.46      0.46      0.45      1000\n","\n","Confusion Matrix:\n","[[132  33  52  33]\n"," [ 89  93  40  28]\n"," [ 93  45  70  42]\n"," [ 44  22  19 165]]\n","KNN : exactitude=0.460, précision=0.469, rappel=0.463, mesure F1=0.454 in temps d'exécution=15.426 s\n","Evaluation de CART\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.44      0.38      0.41       250\n","           2       0.45      0.38      0.41       250\n","           3       0.44      0.45      0.44       250\n","           4       0.67      0.86      0.75       250\n","\n","    accuracy                           0.52      1000\n","   macro avg       0.50      0.52      0.50      1000\n","weighted avg       0.50      0.52      0.50      1000\n","\n","Confusion Matrix:\n","[[ 95  50  72  33]\n"," [ 55  94  58  43]\n"," [ 58  50 112  30]\n"," [  8  15  12 215]]\n","CART : exactitude=0.533, précision=0.517, rappel=0.528, mesure F1=0.513 in temps d'exécution=112.283 s\n","Evaluation de RF\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.52      0.56      0.54       250\n","           2       0.59      0.60      0.60       250\n","           3       0.53      0.54      0.53       250\n","           4       0.95      0.84      0.89       250\n","\n","    accuracy                           0.64      1000\n","   macro avg       0.65      0.64      0.64      1000\n","weighted avg       0.65      0.64      0.64      1000\n","\n","Confusion Matrix:\n","[[140  50  57   3]\n"," [ 51 151  46   2]\n"," [ 70  39 135   6]\n"," [ 10  14  17 209]]\n","RF : exactitude=0.632, précision=0.654, rappel=0.612, mesure F1=0.635 in temps d'exécution=123.867 s\n","Evaluation de SVM\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.52      0.45      0.48       250\n","           2       0.54      0.59      0.57       250\n","           3       0.48      0.58      0.52       250\n","           4       0.97      0.83      0.90       250\n","\n","    accuracy                           0.61      1000\n","   macro avg       0.63      0.61      0.62      1000\n","weighted avg       0.63      0.61      0.62      1000\n","\n","Confusion Matrix:\n","[[113  54  81   2]\n"," [ 37 147  64   2]\n"," [ 50  54 144   2]\n"," [ 16  15  11 208]]\n","SVM : exactitude=0.612, précision=0.634, rappel=0.617, mesure F1=0.617 in temps d'exécution=870.837 s\n"]}],"source":["ma_fonction(True, True, False, True, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6R9t3L5dqzqc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682707880602,"user_tz":-120,"elapsed":1847528,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}},"outputId":"ea3ea4e8-39ab-416b-9ee0-02f8798a6d4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluation de MultinomialNB\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.41      0.67      0.51       250\n","           2       0.68      0.47      0.56       250\n","           3       0.46      0.35      0.40       250\n","           4       0.81      0.77      0.79       250\n","\n","    accuracy                           0.56      1000\n","   macro avg       0.59      0.56      0.56      1000\n","weighted avg       0.59      0.56      0.56      1000\n","\n","Confusion Matrix:\n","[[167  25  49   9]\n"," [ 77 117  39  17]\n"," [125  19  88  18]\n"," [ 34  10  14 192]]\n","MultinomialNB : exactitude=0.564, précision=0.607, rappel=0.571, mesure F1=0.563 in temps d'exécution=7.028 s\n","Evaluation de LR\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.52      0.48      0.50       250\n","           2       0.57      0.60      0.59       250\n","           3       0.49      0.53      0.51       250\n","           4       0.86      0.82      0.84       250\n","\n","    accuracy                           0.61      1000\n","   macro avg       0.61      0.61      0.61      1000\n","weighted avg       0.61      0.61      0.61      1000\n","\n","Confusion Matrix:\n","[[119  51  70  10]\n"," [ 36 151  51  12]\n"," [ 61  47 132  10]\n"," [ 11  17  18 204]]\n","LR : exactitude=0.606, précision=0.615, rappel=0.609, mesure F1=0.606 in temps d'exécution=375.997 s\n","Evaluation de KNN\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.38      0.53      0.44       250\n","           2       0.51      0.42      0.46       250\n","           3       0.41      0.31      0.35       250\n","           4       0.61      0.63      0.62       250\n","\n","    accuracy                           0.47      1000\n","   macro avg       0.48      0.47      0.47      1000\n","weighted avg       0.48      0.47      0.47      1000\n","\n","Confusion Matrix:\n","[[133  34  51  32]\n"," [ 78 105  39  28]\n"," [ 90  43  77  40]\n"," [ 49  25  19 157]]\n","KNN : exactitude=0.472, précision=0.481, rappel=0.473, mesure F1=0.468 in temps d'exécution=14.432 s\n","Evaluation de CART\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.44      0.42      0.43       250\n","           2       0.46      0.42      0.44       250\n","           3       0.42      0.37      0.39       250\n","           4       0.69      0.85      0.76       250\n","\n","    accuracy                           0.52      1000\n","   macro avg       0.50      0.52      0.51      1000\n","weighted avg       0.50      0.52      0.51      1000\n","\n","Confusion Matrix:\n","[[104  54  63  29]\n"," [ 60 106  49  35]\n"," [ 64  61  93  32]\n"," [ 11   9  17 213]]\n","CART : exactitude=0.530, précision=0.516, rappel=0.530, mesure F1=0.501 in temps d'exécution=167.845 s\n","Evaluation de RF\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.52      0.55      0.53       250\n","           2       0.57      0.59      0.58       250\n","           3       0.50      0.52      0.51       250\n","           4       0.95      0.83      0.89       250\n","\n","    accuracy                           0.62      1000\n","   macro avg       0.64      0.62      0.63      1000\n","weighted avg       0.64      0.62      0.63      1000\n","\n","Confusion Matrix:\n","[[137  47  61   5]\n"," [ 47 148  52   3]\n"," [ 68  49 130   3]\n"," [ 12  14  16 208]]\n","RF : exactitude=0.609, précision=0.641, rappel=0.623, mesure F1=0.610 in temps d'exécution=188.069 s\n","Evaluation de SVM\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.53      0.44      0.48       250\n","           2       0.57      0.61      0.59       250\n","           3       0.49      0.60      0.54       250\n","           4       0.97      0.83      0.90       250\n","\n","    accuracy                           0.62      1000\n","   macro avg       0.64      0.62      0.63      1000\n","weighted avg       0.64      0.62      0.63      1000\n","\n","Confusion Matrix:\n","[[111  53  84   2]\n"," [ 35 152  61   2]\n"," [ 49  48 151   2]\n"," [ 13  16  13 208]]\n","SVM : exactitude=0.622, précision=0.646, rappel=0.627, mesure F1=0.626 in temps d'exécution=1087.889 s\n"]}],"source":["ma_fonction(True, True, False, False, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1w6J6QNqztF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682709636125,"user_tz":-120,"elapsed":1755528,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}},"outputId":"cf21e9cc-f93e-49ef-9067-f25bb77ce081"},"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluation de MultinomialNB\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.42      0.66      0.51       250\n","           2       0.66      0.47      0.55       250\n","           3       0.46      0.35      0.39       250\n","           4       0.80      0.76      0.78       250\n","\n","    accuracy                           0.56      1000\n","   macro avg       0.58      0.56      0.56      1000\n","weighted avg       0.58      0.56      0.56      1000\n","\n","Confusion Matrix:\n","[[164  26  51   9]\n"," [ 74 118  39  19]\n"," [120  24  87  19]\n"," [ 35  10  14 191]]\n","MultinomialNB : exactitude=0.560, précision=0.598, rappel=0.567, mesure F1=0.558 in temps d'exécution=7.230 s\n","Evaluation de LR\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.53      0.49      0.51       250\n","           2       0.58      0.61      0.59       250\n","           3       0.49      0.53      0.51       250\n","           4       0.86      0.81      0.84       250\n","\n","    accuracy                           0.61      1000\n","   macro avg       0.62      0.61      0.61      1000\n","weighted avg       0.62      0.61      0.61      1000\n","\n","Confusion Matrix:\n","[[122  50  69   9]\n"," [ 34 153  51  12]\n"," [ 61  46 132  11]\n"," [ 12  17  18 203]]\n","LR : exactitude=0.610, précision=0.619, rappel=0.612, mesure F1=0.609 in temps d'exécution=346.209 s\n","Evaluation de KNN\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.38      0.53      0.44       250\n","           2       0.51      0.42      0.46       250\n","           3       0.41      0.31      0.35       250\n","           4       0.62      0.64      0.63       250\n","\n","    accuracy                           0.47      1000\n","   macro avg       0.48      0.47      0.47      1000\n","weighted avg       0.48      0.47      0.47      1000\n","\n","Confusion Matrix:\n","[[132  34  52  32]\n"," [ 79 104  40  27]\n"," [ 90  44  77  39]\n"," [ 51  20  18 161]]\n","KNN : exactitude=0.474, précision=0.484, rappel=0.475, mesure F1=0.470 in temps d'exécution=14.217 s\n","Evaluation de CART\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.46      0.45      0.46       250\n","           2       0.47      0.37      0.42       250\n","           3       0.44      0.44      0.44       250\n","           4       0.69      0.86      0.77       250\n","\n","    accuracy                           0.53      1000\n","   macro avg       0.52      0.53      0.52      1000\n","weighted avg       0.52      0.53      0.52      1000\n","\n","Confusion Matrix:\n","[[113  34  72  31]\n"," [ 70  93  55  32]\n"," [ 55  54 109  32]\n"," [  8  17  10 215]]\n","CART : exactitude=0.530, précision=0.519, rappel=0.537, mesure F1=0.506 in temps d'exécution=176.181 s\n","Evaluation de RF\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.52      0.54      0.53       250\n","           2       0.55      0.57      0.56       250\n","           3       0.51      0.53      0.52       250\n","           4       0.95      0.84      0.89       250\n","\n","    accuracy                           0.62      1000\n","   macro avg       0.63      0.62      0.63      1000\n","weighted avg       0.63      0.62      0.63      1000\n","\n","Confusion Matrix:\n","[[136  48  64   2]\n"," [ 52 143  50   5]\n"," [ 60  54 133   3]\n"," [ 13  15  13 209]]\n","RF : exactitude=0.598, précision=0.647, rappel=0.636, mesure F1=0.630 in temps d'exécution=189.404 s\n","Evaluation de SVM\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.52      0.44      0.48       250\n","           2       0.57      0.61      0.59       250\n","           3       0.49      0.60      0.54       250\n","           4       0.97      0.83      0.90       250\n","\n","    accuracy                           0.62      1000\n","   macro avg       0.64      0.62      0.63      1000\n","weighted avg       0.64      0.62      0.63      1000\n","\n","Confusion Matrix:\n","[[110  54  84   2]\n"," [ 34 152  62   2]\n"," [ 51  46 151   2]\n"," [ 15  16  11 208]]\n","SVM : exactitude=0.621, précision=0.644, rappel=0.626, mesure F1=0.625 in temps d'exécution=1017.643 s\n"]}],"source":["ma_fonction(True, True, True, False, True)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}